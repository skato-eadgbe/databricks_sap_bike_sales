import os
from databricks import sql
from databricks.sdk.core import Config
import streamlit as st
import pandas as pd
from datetime import datetime, date

# Ensure environment variable is set correctly
assert os.getenv('DATABRICKS_WAREHOUSE_ID'), "DATABRICKS_WAREHOUSE_ID must be set in app.yaml."

# Databricks config
cfg = Config()

# Query the SQL warehouse with the user credentials
def sql_query_with_user_token(query: str, user_token: str) -> pd.DataFrame:
    """Execute a SQL query and return the result as a pandas DataFrame."""
    with sql.connect(
        server_hostname=cfg.host,
        http_path=f"/sql/1.0/warehouses/{cfg.warehouse_id}",
        access_token=user_token  # Pass the user token into the SQL connect to query on behalf of user
    ) as connection:
        with connection.cursor() as cursor:
            cursor.execute(query)
            return cursor.fetchall_arrow().to_pandas()

st.set_page_config(page_title="å¾“æ¥­å“¡åˆ¥å£²ä¸Šé›†è¨ˆ", layout="wide")

st.header("å¾“æ¥­å“¡åˆ¥å£²ä¸Šé›†è¨ˆ ğŸ“Š")

# Extract user access token from the request headers
user_token = st.context.headers.get('X-Forwarded-Access-Token')

# Date range selection
st.sidebar.header("æœŸé–“è¨­å®š")
start_date = st.sidebar.date_input("é–‹å§‹æ—¥", value=date(2023, 1, 1))
end_date = st.sidebar.date_input("çµ‚äº†æ—¥", value=date.today())

# Convert dates to string format for SQL query
start_date_str = start_date.strftime('%Y-%m-%d')
end_date_str = end_date.strftime('%Y-%m-%d')

# SQL query to get employee sales data
employee_sales_query = f"""
SELECT 
    e.EMPLOYEEID,
    e.NAME_FIRST,
    e.NAME_LAST,
    e.NAME_FIRST || ' ' || e.NAME_LAST as FULL_NAME,
    COUNT(DISTINCT so.SALESORDERID) as ORDER_COUNT,
    SUM(so.NETAMOUNT) as TOTAL_SALES,
    SUM(so.GROSSAMOUNT) as TOTAL_GROSS,
    SUM(so.TAXAMOUNT) as TOTAL_TAX,
    AVG(so.NETAMOUNT) as AVERAGE_ORDER_VALUE,
    MIN(so.CREATEDAT) as FIRST_ORDER_DATE,
    MAX(so.CREATEDAT) as LAST_ORDER_DATE
FROM skato.bikes_sales_content.employees e
LEFT JOIN skato.bikes_sales_content.salesorders so ON e.EMPLOYEEID = so.CREATEDBY
WHERE so.CREATEDAT BETWEEN '{start_date_str}' AND '{end_date_str}'
GROUP BY e.EMPLOYEEID, e.NAME_FIRST, e.NAME_LAST
ORDER BY TOTAL_SALES DESC
"""

try:
    # Execute the query
    with st.spinner('ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...'):
        sales_data = sql_query_with_user_token(employee_sales_query, user_token=user_token)
    
    if not sales_data.empty:
        # Display summary metrics
        st.subheader(f"æœŸé–“: {start_date_str} ï½ {end_date_str}")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("å£²ä¸Šå®Ÿç¸¾ã®ã‚ã‚‹å¾“æ¥­å“¡æ•°", len(sales_data))
        
        with col2:
            total_sales = sales_data['TOTAL_SALES'].sum()
            st.metric("ç·å£²ä¸Š", f"${total_sales:,.2f}")
        
        with col3:
            total_orders = sales_data['ORDER_COUNT'].sum()
            st.metric("ç·æ³¨æ–‡æ•°", f"{total_orders:,}")
        
        with col4:
            avg_order_value = sales_data['AVERAGE_ORDER_VALUE'].mean()
            st.metric("å¹³å‡æ³¨æ–‡å˜ä¾¡", f"${avg_order_value:,.2f}")
        
        # Display top performers
        st.subheader("å£²ä¸Šä¸Šä½å¾“æ¥­å“¡")
        
        # Format the data for display
        display_data = sales_data.copy()
        display_data['TOTAL_SALES'] = display_data['TOTAL_SALES'].apply(lambda x: f"${x:,.2f}")
        display_data['TOTAL_GROSS'] = display_data['TOTAL_GROSS'].apply(lambda x: f"${x:,.2f}")
        display_data['TOTAL_TAX'] = display_data['TOTAL_TAX'].apply(lambda x: f"${x:,.2f}")
        display_data['AVERAGE_ORDER_VALUE'] = display_data['AVERAGE_ORDER_VALUE'].apply(lambda x: f"${x:,.2f}")
        
        # Rename columns for display
        display_data = display_data.rename(columns={
            'EMPLOYEEID': 'å¾“æ¥­å“¡ID',
            'FULL_NAME': 'æ°å',
            'ORDER_COUNT': 'æ³¨æ–‡æ•°',
            'TOTAL_SALES': 'ç´”å£²ä¸Š',
            'TOTAL_GROSS': 'ç·å£²ä¸Š',
            'TOTAL_TAX': 'ç¨é¡',
            'AVERAGE_ORDER_VALUE': 'å¹³å‡æ³¨æ–‡å˜ä¾¡',
            'FIRST_ORDER_DATE': 'åˆå›æ³¨æ–‡æ—¥',
            'LAST_ORDER_DATE': 'æœ€çµ‚æ³¨æ–‡æ—¥'
        })
        
        # Display the data table
        st.dataframe(
            display_data[['å¾“æ¥­å“¡ID', 'æ°å', 'æ³¨æ–‡æ•°', 'ç´”å£²ä¸Š', 'ç·å£²ä¸Š', 'ç¨é¡', 'å¹³å‡æ³¨æ–‡å˜ä¾¡', 'åˆå›æ³¨æ–‡æ—¥', 'æœ€çµ‚æ³¨æ–‡æ—¥']], 
            use_container_width=True
        )
        
        # Charts
        st.subheader("å£²ä¸Šãƒãƒ£ãƒ¼ãƒˆ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("å¾“æ¥­å“¡åˆ¥å£²ä¸Š (TOP 10)")
            top_10 = sales_data.head(10)
            chart_data = top_10.set_index('FULL_NAME')['TOTAL_SALES']
            st.bar_chart(chart_data)
        
        with col2:
            st.subheader("å¾“æ¥­å“¡åˆ¥æ³¨æ–‡æ•° (TOP 10)")
            chart_data = top_10.set_index('FULL_NAME')['ORDER_COUNT']
            st.bar_chart(chart_data)
    
    else:
        st.warning("æŒ‡å®šã•ã‚ŒãŸæœŸé–“å†…ã«å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

except Exception as e:
    st.error(f"ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®æ¥ç¶šã¾ãŸã¯ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

# Additional information
st.sidebar.markdown("---")
st.sidebar.markdown("### ä½¿ç”¨æ–¹æ³•")
st.sidebar.markdown("1. é–‹å§‹æ—¥ã¨çµ‚äº†æ—¥ã‚’é¸æŠã—ã¦ãã ã•ã„")
st.sidebar.markdown("2. å¾“æ¥­å“¡åˆ¥ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒè‡ªå‹•çš„ã«è¡¨ç¤ºã•ã‚Œã¾ã™")
st.sidebar.markdown("3. å£²ä¸Šå®Ÿç¸¾ã¯ç´”å£²ä¸Šé¡ã§é™é †ã«è¡¨ç¤ºã•ã‚Œã¾ã™")